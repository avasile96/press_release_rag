# Environment variables

OLLAMA_HOST=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_CHAT_MODEL=llama3
CHUNK_SIZE=1000
CHUNK_OVERLAP=150
TOP_K=4
TEMPERATURE=0.2
MAX_TOKENS=1024
